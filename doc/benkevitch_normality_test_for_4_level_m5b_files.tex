\documentclass[letterpaper,twoside,12pt]{article}
\usepackage[dvips]{graphicx}
\usepackage[margin=0.8in]{geometry}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[T1]{fontenc}
\usepackage{natbib}
\usepackage{authblk}
%\usepackage{url}
%\usepackage{times}
\usepackage{textcomp}
\bibliographystyle{agu08}

\newcommand{\ud}{\mathrm d}
\newcommand{\uj}{\mathrm{j}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\Real}{\mathrm{Re}}
\newcommand{\Imag}{\mathrm{Im}}
\newcommand{\dif}{\mathrm{d}}
\newcommand{\sigsig}{\sigma_1\sigma_2}
\newcommand{\varss}{\varsigma_1\varsigma_2}
\newcommand{\hvarss}{\hat{\varsigma}_1 \hat{\varsigma}_2}
\newcommand{\twodots}{\mathinner {\ldotp \ldotp}}
\newcommand{\midtilde}{\raisebox{0.5ex}{\texttildelow}}

\DeclareMathOperator\erf{erf}

\title{Normality Test for 2-bit Stream Data in Mark-5 Files}

\author[1]{L. V. Benkevitch}
\affil[1]{\small MIT Haystack observatory, Westford, MA 01886, USA.}


\begin{document}

\maketitle

\begin{abstract}
The radio astronomy data from a single dish are recorded in M5B (Mark-5) or VDIF formatted files. The recorded data are supposed to be Gaussian white noise. A corrupted data segment can be spotted at the output of correlation stage. However, the correlation is expensive and vastly increases the bulk of data to be analyzed for spurious parts. Here we consider a problem of finding non~Gaussian (or non-normal) single-dish data segments in M5B files.

The problem may be thought about from a security standpoint. Suppose someone (a malicious character) wishes to hack a system and figures an approach would be to embed some malicious code in. Is it possible to detect the embedded (non-Gaussian) data within a frame or multiple frames before the correlator? Also, even though an algorithm can be determined, is it possible to make its implementation fast enough? The data files are large (up to a hundred gigabytes).

Our solution is based on Pearson's $\chi^2$ test. The null hypothesis states that the data in file  are consistent with the normal distribution. If the data in a part of the file do not pass the test at the significance level 0.05, the null hypothesis is rejected, and the data fragment is flagged.

The algorithm runs on the GPU (Graphics Processing Unit), which provides high speed computations.
\end{abstract}


\section{Quantization and M5B Data Structure}

The analog signal from a single antenna/dish is supposed to be Gaussian noise $N(\mu,\sigma)$ with the expectation $\mu$ and standard deviation (rms) $\sigma$ distributed according to the normal law with the probability density function (PDF):

\begin{equation}
  \label{normal_pdf}
  N(\mu,\sigma) =  \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}.
\end{equation}

The signal is centered to ensure zero $\mu$ and its band is filtered into 16 frequency channels each of which is passed through the 4-level quantizer with the characteristic shown in Fig.~\ref{quant4lvl}.  The quantizer has just three switching thresholds, $-\theta$, 0, and $\theta$, so it is characterized with the only parameter, the adjustable quantization threshold $\pm\theta$. Note that the hardware deals with voltage thresholds, $\pm v_0$, but $\theta$ is expressed in the signal STDs, thus it is dimensionless, $\theta = v_0/\sigma$. The quantizer output only takes four values as in Tab.~\ref{quant_io}. These values are saved in the M5B file.


\begin{figure}[ht!]
  \begin{center}
  \includegraphics[width=25pc]{fig_4_Level_Quantization_Pattern_impr.eps}
  %\noindent\includegraphics[width=20pc]{fig_4_Level_Quantization_Pattern_impr.eps}
  %\includegraphics[width=\linewidth]{}
  \caption{\small 4-level quantization.}
  \label{quant4lvl}
  \end{center}
\end{figure}


\begin{table}[ht!]
  \begin{center}
    \caption{Quantizer}
    \label{quant_io}
    \begin{tabular}{c|c}
      \textbf{Input, $x$} & \textbf{Output, $\hat{x}$} \\
      \hline
      $-\infty$ to $-\theta$ & 0 \\
      $-\theta$ to 0         & 1 \\
      0 to $\theta$          & 2 \\
      $\theta$ to $+\infty$  & 3 \\
    \end{tabular}
  \end{center}
\end{table}


The M5B file can be considered as an array of 10016-byte frames. Each frame consists of 2504 32-bit words (\verb@unsigned int@ or  \verb@uint@ in C/C++). The first 4 words comprise the frame header, so a frame has 2500 words of pure data. Each 32-bit data word is subdivided into 16 2-bit channels, numbered from 0 to 15. The header contains the sync word \verb@0xdec0de5c@, 23-bit long frame number within second (reset to zero each new second), one flag bit to tag the frame invalid, 8-bit long channel ID, BCD Time Code Word 1 (‘JJJSSSSS’), BCD Time Code Word 2 (‘.SSSS’), and  16-bit CRCC.

Unfortunately, the header does \emph{not} contain the quantization threshold value $\theta = v_0/\sigma$, which is necessary for the statistical testing. In order to estimate $\theta$, the algorithm has to spend precious time on its 1D search as will be described further. 




\section{Statistical Testing Data Normality Using $\chi^2$}

We need to test if the data in each of the 16 channels are sampled from a normally distributed population (the null hypothesis) or not (the alternative hypothesis). In each frame and channel, there are $N=$ 2500 data samples divided into $n=4$ categories by their values, 0, 1, 2, and 3. The counts of data samples in each category form the 4 histogram bins $B_i, i=\overline{0 \twodots 3}$, so $\sum_{i=0}^3 B_i = N$. The Pearson's $\chi^2$ test is based on comparing the observed data counts with the expected (theoretical) counts $E_i, i=\overline{0 \twodots 3}$ obtained from the normal PDF~\eqref{normal_pdf} as $E_i = Np_i$. Here $p_i$ is the probability that a random value sampled from $N(0,\sigma)$ is within the $i$-th interval. The intervals are given in Tab.~\ref{quant_io}, where $i$ is one of the Output values. $\ldots\cdots\ldotp\ldotp$

For each data frame the value of the test-statistic is calculated as

\begin{equation}
  \label{x2_calc}
  X^2 = \sum_{i=0}^3 \frac{(B_i - E_i)^2}{E_i}.
\end{equation}


The $X^2$ test-statistic asymptotically approaches the $\chi^2_{k=3}$ distribution, where $k = n - 1 = 3$ is the number of degrees of freedom. The $\chi^2_{k=3}$ PDF is shown in Fig.~\ref{chi2_pdf}. The statistic $X^2$ is a random value showing how close are the observation frequencies $B_i$ to the perfect, theoretical frequencies $E_i$. The $\chi^2_{k=3}$ PDF has maximum at $X^2=1$ and the mean at $X^2=k=3$. This means that if $X^2$ is distributed as $\chi^2_{k=3}$ its most probable random values will be concentrated somewhere around the mean 3 and not much further. But how much further? The area under the $\chi^2_{k=3}$ PDF curve in Fig.~\ref{chi2_pdf} over an interval $[a,b]$ equals to the probability that the random value will appear within this interval. If we want to be 95\% confident that the data is distributed normally, $X^2$ cannot exceed the critical value $\chi^2_{cr}$ such that the probability for $X^2$ to appear within the interval $[0 \twodots \chi^2_{cr}]$ is $p=0.95$. The critical $\chi^2_{k=3}$ value can be calculated as the value of $\chi^2$ Probability Point Function or PPF, the inverse of the $\chi^2$ Cumulative Distribution Function or CDF. In Python this is done as $\verb@scipy.stats.chi2.ppf(1-alpha, k)@$, where $\alpha = 0.05$ is the level of significance. In our case $\chi^2_{cr} = 7.81$. 

\begin{figure}[ht!]
  \begin{center}
  \includegraphics[width=25pc]{fig_chi2_pdf.eps}
  %\noindent\includegraphics[width=20pc]{fig_4_Level_Quantization_Pattern_impr.eps}
  %\includegraphics[width=\linewidth]{}
  \caption{\small Chi-squared distribution function.}
  \label{chi2_pdf}
  \end{center}
\end{figure}

Thus, our algorithm flags a channel data in frame as non-Gaussian if its $X^2 > 7.81$, the probability of incorrectly rejecting the null hypothesis being $\alpha = 0.05$. In Fig.~\ref{chi2_pdf} this is the red-filled area with the probability 0.05 over the range $[\chi^2_{cr} \twodots +\infty)$. 



\section{Estimation of Quantization Threshold Using 1D Search}

As mentioned, the M5B files do not provide the values of quantization threshold $\theta$, which is continuously being adjusted and can differ from one frame to the next. Assuming the data are sampled from the normally distributed population we can hypothesize that the $\theta_{\text{opt}}$ value that provides the best fit of the observed frequencies $B_i$ to the normal frequencies $E_i$ can be a good estimate of the actual $\theta$ established at the quantization time.

One can notice that the $X^2$ statistics in Eq.~\eqref{x2_calc} is a function of a single variable $\theta$: 

\begin{equation}
  \label{x2_func_of_theta}
  X^2(\theta) = \sum_{i=0}^3 \frac{(B_i - E_i(\theta))^2}{E_i(\theta)},
\end{equation}

where the normal frequencies $E_i$ are dependent on the quantization thresholds positions:

\begin{equation*}
  \label{norm_freq}
  E_{0\twodots3}(\theta) = N \cdot \left[\Phi(-\theta), \; \frac{1}{2}-\Phi(-\theta), \; 
                             \frac{1}{2}-\Phi(-\theta), \; \Phi(-\theta) \right],
\end{equation*}

as shown in Fig.~\ref{npdf_areas}, and $\Phi(x)$ is the normal CDF with $\mu=0$ and $\sigma=1$:

\begin{equation}
  \label{ncdf}
  \Phi(x) = \frac{1}{2} \left[1 + \erf \left( \frac{x}{\sqrt{2}} \right) \right].
\end{equation}


\begin{figure}[ht!]
  \begin{center}
  \includegraphics[width=25pc]{fig_npdf_areas.eps}
  \caption{\small  $\theta = 0.7988$, which can be used as an estimate for the actual threshold used in the analog signal quantization.}
  \label{npdf_areas}
  \end{center}
\end{figure}

Fig.~\ref{optimum_theta} shows that the curve $y = X^2(\theta)$ has the only minimum. Thus, the best fit of the normal frequencies $E_i$ to the observed frequencies $B_i$ can be reached at the single $\theta=\theta_\text{opt}$ value that provides minimum to $X^2(\theta)$. 

We have used a fast-converging Brent's algorithm for one-dimensional search. It is a combination of the golden section search at the beginning and the parabolic interpolation when the process is close enough to the minimum.


\begin{figure}[ht!]
  \begin{center}
  \includegraphics[width=25pc]{fig_optimal_quantization_threshold.eps}
  \caption{\small $X^2(\theta)$ from Eq.~\eqref{x2_func_of_theta} as the measure of error between the observed, $B_i$, and normal, $E_i$ frequencies for the range of quantization tresholds $[0.4 \mathinner{\ldotp\ldotp}1.5]$. The curve has minimum at $\theta = 0.7988$, which can be used as an estimate for the actual threshold used in the analog signal quantization.}
  \label{optimum_theta}
  \end{center}
\end{figure}


\section{Using Graphics Processing Units (GPU)}

The Graphics Processing Units with their hundreds and thousands of processor cores and multiple memory channels allow 1 to 3 orders of magnitude speed-up of the common algorithms. There are two major software frameworks, CUDA and OpenCL. CUDA is developed specifically for the Nvidia GPUs. OpenCL can be used on many parallel architectures. OpenCL is the only option for the AMD GPUs.

In both frameworks, the application code consists of two parts. One part is executed on the host PC. It reads the M5B files, prepares the GPU, uploads there the codes and the M5B data, starts the computations on the GPU, downloads the results from the GPU to the host memory, and saves them to the disk. The other part of code is executed in parallel on the multiple GPU cores. The programs executed on the GPU are called kernels. 

In both frameworks we use single precision floating point arithmetics, which provides the fastest computations.

In the both frameworks, the kernels are written in the C language subsets with some extensions. The host code uses CUDA or OpenCL API. It can be written in C/C++ and some other languages. However, Python is always preferred to make life easier. We use Python wrappers for the both frameworks: PyCUDA and PyOpenCL, and the host part of the NormTest software is written in Python. 


\section{NormTest Software}

\subsection{gpu\_m5b.py}

The \verb@gpu_m5b.py@ module defines the only class \verb@Normtest@ that integrates in itself all the normality testing mechanisms. When imported from the \verb@gpu_m5b@ module, \verb@Normtest@ class probes the hardware and automatically determines which framework to use. If it detects an AMD GPU, it uses OpenCL. If an Nvidia GPU is detected, the software uses CUDA. In case both frameworks are installed, it prefers CUDA since it is \midtilde 1.5  times faster than OpenCL. Thus this class provides "transparent" access to the GPU independent of the software framework used. Current version of the software can use only one GPU, however, in future it is possible to employ multiple GPUs on the same motherboard, even using different frameworks. 

The \verb@Normtest@ class is not intended to create multiple class instances (although it is surely possible). It provides a "class method" \verb@do_m5b()@ with one argument, a string with M5B filename. It runs the normality test on the available GPU using the software framework selected. If the M5B file is large and it does not fit into either system RAM or the GPU RAM, it is processed in chunks. The results are saved in 5 binary files.  The files have the following names: \\
    \verb@nt_<data>_<framework>_<m5b_basename>_<timestamp>.bin@, \\
where \verb@<data>@ is the result types: \\

\verb@quantl: dtype=np.float32, shape=(n_frames,16,4)@, 4 quantiles for 16 channels; \\
chi2:   dtype=np.float32, shape=(n_frames,16), chi^2 for 16 channels;
thresh: dtype=np.float32, shape=(n_frames,16), quantization thresholds found
        for 16 channels;
flag:   dtype=np.uint16, shape=(n_frames,16), flags for 16 channels; 
niter:  dtype=np.uint16, shape=(n_frames,16), number of iterations of Brent's
        optimization method used to find the optimal quantization threshold
        for 16 channels;
@
%
%   
%Example:
%   
%from gpu_m5b import Normtest as nt
%nt.do_m5b("rd1910_wz_268-1811.m5b")
%
%Empirically, it has been found that the best performance is achieved 
%with 8 threads per block (in CUDA terminology), and, which is the same, 
%8 work items per work group (in OpenCL terms). However, this number can 
%be changed using the nthreads parameter. For example:
%
%nt.do_m5b("rd1910_wz_268-1811.m5b", nthreads=64)
%
%
%---------------------------
%
%This directory also contains two older versions ofthe Python scripts for
%normality testing using the GPUs. One of them, normtest_m5b_cuda.py, uses
%PyCuda and can be only run on Nvidia GPUs with CUDA and PyCuda installed.
%The other one uses PyOpenCL and can be run on both AMD and Nvidia GPUs as
%long as OpenCL and PyOpenCL are installed. Note that CUDA works ~1.5 times
%faster than OpenCL.
%
%Both scripts cannot process M5B files in chunks, and therefore they are unable
%to process large M5B files.
%
%Currently, the scripts use positional command line parameters.
%
%2. normtest_m5b_cuda.py:
%
%Normality (Gaussianity) test for M5B files on Nvidia GPU using PyCUDA package.
%Single precision floats.
%
%Requires:
%
%ker_m5b_gauss_test.cu, CUDA kernel.
%fminbndf.cu, 1D optimization code.
%
%Usage:
%
%\$ python normtest_m5b_cuda.py <m5b-file-name> [<of threads per block>] [-s]
%
%Or, from IPython:
%
%\$ ipython --pylab
%
%%run normtest_m5b_cuda.py <m5b-file-name> [<# of threads per block>] [-s]
%
%If <# of threads> is not specified, the optimal (appearingly) 8 is used.
%
%If "-s" is present at the end of command line the results are saved in text
%files in the subdirectory result/ with the names:
%   thresholds_*.txt
%   residuals_*.txt
%   n_iterations_*.txt
%   flags_*.txt
%   quantiles_*.txt
%
%Examples:
%
%\$ python normtest_m5b_cuda.py rd1910_wz_268-1811.m5b
%\$ python normtest_m5b_cuda.py rd1910_wz_268-1811.m5b 8
%\$ python normtest_m5b_cuda.py rd1910_wz_268-1811.m5b 8 -s
%
%Note that saving the result files may take long time.
%
%
%
%
%3. normtest_m5b_ocl.py:
%
%Normality (Gaussianity) test for M5B files on a GPU using PyOpenCL package.
%Single precision floats.
%
%Requires:
%ker_m5b_gauss_test.cl, OpenCL kernel.
%fminbndf.cl, 1D optimization code for Nvidia GPUs.
%fminbndf_amd.cl, 1D optimization code for AMD GPUs.
%
%Usage: 
%
%\$ python normtest_m5b_cuda.py <m5b-file-name> [<# of threads per block>] [-s]
%
%Or, from IPython:
%
%\$ ipython --pylab
%
%%run normtest_m5b_ocl_.py <m5b-file-name> [<of threads per block>] [-s]
%
%If <# of threads> is not specified, the optimal (appearingly) 8 is used.
%
%If "-s" is present at the end of command line the results are saved in text
%files in the subdirectory result/ with the names:
%   thresholds_*.txt
%   residuals_*.txt
%   n_iterations_*.txt
%   flags_*.txt
%   quantiles_*.txt
%
%Examples:
%")
%\$ python normtest_m5b_ocl.py rd1910_wz_268-1811.m5b
%\$ python normtest_m5b_ocl.py rd1910_wz_268-1811.m5b 8
%\$ python normtest_m5b_ocl.py rd1910_wz_268-1811.m5b 8 -s
%
%Note that saving the result files may take long time.
%
%
%----------------------------
%
%Ancillary scripts:
%
%4. plot_m5b_thrange.py
%
%Plots squared error (the residual) between M5B Data and four quantiles of the
%standard normal distribution over the range [0.4 .. 1.5] of input sample
%thresholds. The plot obviously has its minimum at the threshold +-0.817/STD
%marked with the red dot.
%
%
%5. test_m5b.py
%
%Calculates the observed Chi^2 and compares it with the Chi^2 critical value at
%the significance level 0.05 for the degrees of freedom 3 (we have 4 quantiles,
%so df = 4 - 1 = 3).
%
%Plots histograms of the observed data and the theoretical normal distribution
%to compare.
%
%Running:
%%run test_m5b.py <m5b_filename>
%
%
%6. plot_m5b_hist.py
%
%Plots two histograms of the results from gpu_m5b.py for the whole 
%M5B (or M5A) file: 
%6.1. Distribution of chi^2 and a red marker showing position of the critical
%     chi^2 value (7.81), as well as the percent of chi^2 exceeding it.
%6.2. Distribution of the optimal quantization thresholds and a red marker
%     showing position of the critical threshold value (0.6745 rms), as well as
%     the percent of the thresholds that failed to reach it.
%
%
%7. inspect_nt.py
%
%This script creates 4x4 plots of 16 histograms for each of the 16 channels.
%The plots are for one or several (averaged) frames. The histograms are compared
%with the normal distribution curves showing approximately from what size
%quantiles the observation data are drawn. For each plot the chi^2 is printed.
%
%The data are read from the *.bin files created with the gpu_m5b_chi2.py.
%
%Running:
%
%%run inspect_nt.py <m5b_filename> <timestamp> <start_frame_#> <#_of_frames> 
%
%Some interesting frames:
%7.1. These plots show that the Pearson's chi^2 cannot be used. The histograms 
%are very far from the normal distributions, but most of the chi^2 values
%are very small and signal "normality"
%%run inspect_nt.py rd1903_ft_100-0950.m5b 025 97737 1
%
%7.2. These plots are definitely from the uniform distributions, and yet, most
%of the chi^2 values are very small and signal "normality". The pearson's
%criterion also does not work.
%%run inspect_nt.py rd1903_ft_100-0950.m5b 025 4 1
%%run inspect_nt.py rd1903_ft_100-0950.m5b 025 170578 1
%%run inspect_nt.py rd1903_ft_100-0950.m5b 025 389930 1
%%run inspect_nt.py rd1903_ft_100-0950.m5b 025 6832715 1
%
%7.3. These plots show close to normal histograms with good chi^2 values, i.e.
%< 7.81.
%%run inspect_nt.py rd1910_wz_268-1811.m5b 970 200 1
%%run inspect_nt.py rd1910_ny_269-1404.m5a 395 7139 1
%
%
%8. plot_25pc_npdf_expectations.py
%
%Plots the normal curve N(0,1) divided vertically into 4 equal areas under the 
%curve (25%-quantiles). The division lines are at -0.6745, 0, and +0.6745. 
%For each of the areas, the math expectations are computed, they are at 
%    -1.27, -0.32, 0.32, and 1.27 (in STDs). 
%Thse are the most probable analog signal values before the quantization with
%the *ideal* thresholds -0.6745, 0, and +0.6745, which provide the uniform 
%arrangement of the discrete signal in the 4 bins.  
%
%
%9. skew_kurt.py
%
%Calculates skewness and kurtosis of a frame in M5B or M5A file.
%The data positions (in STDs) are assumed at the 25%-quantile math expectations,
%  mu0 = -1.27, mu1 = -0.32, mu2 = 0.32, and mu3 = 1.27.

\begin{thebibliography}{99}

\bibitem[{\textit{Kiefer}(1953)}]{Kiefer1953} 
{Kiefer}, J.~L. (1953), {Sequential minimax search for a maximum}, \textit{Proceedings of the American Mathematical Society}, \textit{4}, (3), 502-–506, DOI:10.1109/TIT.1967.1053965.

%\bibitem[{\textit{{Brown}}(1967)}]{Brown1967}
%{Brown}, J.~L. (1967), {A Generalized Form of Price's Theorem and Its Converse}, \textit{IEEE Transactions on Information Theory}, \textit{13}, 27--30, \doi{10.1109/TIT.1967.1053965}.
%
%\bibitem[{\textit{{Cooper}}(1970)}]{Cooper1970}
%{Cooper}, B.~F.~C. (1970), {Correlators with two-bit quantization},
%  \textit{Australian Journal of Physics}, \textit{23}, 521--527.
%
%\bibitem[{\textit{{Greisen}}(2003)}]{Greisen2003}
%{Greisen}, E.~W. (2003), {AIPS, the VLA, and the VLBA}, \textit{Information
%  Handling in Astronomy - Historical Vistas}, \textit{285}, 109,
%  \doi{10.1007/0-306-48080-8\_7}.
%
%\bibitem[{\textit{{Hagen} and {Farley}}(1973)}]{Hagen1973}
%{Hagen}, J.~B., and D.~T. {Farley} (1973), {Digital-correlation techniques in
%  radio science.}, \textit{Radio Science}, \textit{8}, 775--784,
%  \doi{10.1029/RS008i008p00775}.
%
%\bibitem[{\textit{{Johnson} et~al.}(2013)\textit{{Johnson}, {Chou}, and
%  {Gwinn}}}]{Johnson2013}
%{Johnson}, M.~D., H.~H. {Chou}, and C.~R. {Gwinn} (2013), {Optimal Correlation
%  Estimators for Quantized Signals}, \textit{Astrophysical Journal},
%  \textit{765}, 135, \doi{10.1088/0004-637X/765/2/135}.
%
%\bibitem[{\textit{{Kulkarni} and {Heiles}}(1980)}]{Kulkarni1980}
%{Kulkarni}, S.~R., and C.~{Heiles} (1980), {How to obtain the true correlation
%  from a 3-level digital correlator}, \textit{Astronomical Journal},
%  \textit{85}, 1413--1420, \doi{10.1086/112815}.
%
%
%
%\bibitem[{\textit{Bracewell}(1986)}]{Bracewell1986}
%Bracewell, R.~N. (1986), \textit{{The Fourier Transform and Its Applications}},
%  2nd, revised ed., 474 pp., WCB/McGraw-Hill, Boston, Massachusetts.
%
%\bibitem[{\textit{Bracewell}(1986)}]{Bracewell1986}
%Bracewell, R.~N. (1986), \textit{{The Fourier Transform and Its Applications}},
%  2nd, revised ed., 474 pp., WCB/McGraw-Hill, Boston, Massachusetts.
%


\end{thebibliography}



\end{document}



