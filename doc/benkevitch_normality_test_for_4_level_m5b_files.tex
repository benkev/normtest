\documentclass[letterpaper,twoside,12pt]{article}
\usepackage[dvips]{graphicx}
\usepackage[margin=0.8in]{geometry}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[T1]{fontenc}
\usepackage{natbib}
\usepackage{authblk}
\bibliographystyle{agu08}

\newcommand{\ud}{\mathrm d}
\newcommand{\uj}{\mathrm{j}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\Real}{\mathrm{Re}}
\newcommand{\Imag}{\mathrm{Im}}
\newcommand{\dif}{\mathrm{d}}
\newcommand{\sigsig}{\sigma_1\sigma_2}
\newcommand{\varss}{\varsigma_1\varsigma_2}
\newcommand{\hvarss}{\hat{\varsigma}_1 \hat{\varsigma}_2}
\newcommand{\twodots}{\mathinner {\ldotp \ldotp}}

\DeclareMathOperator\erf{erf}

\title{Normality Test for 2-bit Stream Data in Mark-5 Files}

\author[1]{L. V. Benkevitch}
\affil[1]{\small MIT Haystack observatory, Westford, MA 01886, USA.}


\begin{document}

\maketitle

\begin{abstract}
The radio astronomy data from a single dish are recorded in M5B (Mark-5) or VDIF formatted files. The recorded data are supposed to be Gaussian white noise. A corrupted data segment can be spotted at the output of correlation stage. However, the correlation is expensive and vastly increases the bulk of data to be analyzed for spurious parts. Here we consider a problem of finding non~Gaussian (or non-normal) single-dish data segments in M5B files.

The problem may be thought about from a security standpoint. Suppose someone (a malicious character) wishes to hack a system and figures an approach would be to embed some malicious code in. Is it possible to detect the embedded (non-Gaussian) data within a frame or multiple frames before the correlator? Also, even though an algorithm can be determined, is it possible to make its implementation fast enough? The data files are large (up to a hundred gigabytes).

Our solution is based on Pearson's $\chi^2$ test. The null hypothesis states that the data in file  are consistent with the normal distribution. If the data in a part of the file do not pass the test at the significance level 0.05, the null hypothesis is rejected, and the data fragment is flagged.

The algorithm runs on the GPU (Graphics Processing Unit), which provides high speed computations.
\end{abstract}


\section{Quantization and M5B Data Structure}

The analog signal from a single antenna/dish is supposed to be Gaussian noise $N(\mu,\sigma)$ with the expectation $\mu$ and standard deviation (rms) $\sigma$ distributed according to the normal law with the probability density function (PDF):

\begin{equation}
  \label{normal_pdf}
  N(\mu,\sigma) =  \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}.
\end{equation}

The signal is centered to ensure zero $\mu$ and its band is filtered into 16 frequency channels each of which is passed through the 4-level quantizer with the characteristic shown in Fig.~\ref{quant4lvl}.  The quantizer has just three switching thresholds, $-\theta$, 0, and $\theta$, so it is characterized with the only parameter, the adjustable quantization threshold $\pm\theta$. Note that the hardware deals with voltage thresholds, $\pm v_0$, but $\theta$ is expressed in the signal STDs, thus it is dimensionless, $\theta = v_0/\sigma$. The quantizer output only takes four values as in Tab.~\ref{quant_io}. These values are saved in the M5B file.


\begin{figure}[ht!]
  \begin{center}
  \includegraphics[width=25pc]{fig_4_Level_Quantization_Pattern_impr.eps}
  %\noindent\includegraphics[width=20pc]{fig_4_Level_Quantization_Pattern_impr.eps}
  %\includegraphics[width=\linewidth]{}
  \caption{\small 4-level quantization.}
  \label{quant4lvl}
  \end{center}
\end{figure}


\begin{table}[ht!]
  \begin{center}
    \caption{Quantizer}
    \label{quant_io}
    \begin{tabular}{c|c}
      \textbf{Input} & \textbf{Output} \\
      \hline
      $-\infty$ to $-\theta$ & 0 \\
      $-\theta$ to 0         & 1 \\
      0 to $\theta$          & 2 \\
      $\theta$ to $+\infty$  & 3 \\
    \end{tabular}
  \end{center}
\end{table}


The M5B file can be considered as an array of 10016-byte frames. Each frame consists of 2504 32-bit words (\verb@unsigned int@ or  \verb@uint@ in C/C++). The first 4 words comprise the frame header, so a frame has 2500 words of pure data. Each 32-bit data word is subdivided into 16 2-bit channels, numbered from 0 to 15. The header contains the sync word \verb@0xdec0de5c@, 23-bit long frame number within second (reset to zero each new second), one flag bit to tag the frame invalid, 8-bit long channel ID, BCD Time Code Word 1 (‘JJJSSSSS’), BCD Time Code Word 2 (‘.SSSS’), and  16-bit CRCC.

Unfortunately, the header does \emph{not} contain the quantization threshold value $\theta = v_0/\sigma$, which is necessary for the statistical testing. In order to estimate $\theta$, the algorithm has to spend precious time on its linear search as will be described further. 




\section{Statistical Testing Data Normality Using $\chi^2$}

We need to test if the data in each of the 16 channels are sampled from a normally distributed population (the null hypothesis) or not (the alternative hypothesis). In each frame and channel, there are $N=$ 2500 data samples divided into $n=4$ categories by their values, 0, 1, 2, and 3. The counts of data samples in each category form the 4 histogram bins $B_i, i=\overline{0 \twodots 3}$, so $\sum_{i=0}^3 B_i = N$. The Pearson's $\chi^2$ test is based on comparing the observed data counts with the expected (theoretical) counts $E_i, i=\overline{0 \twodots 3}$ obtained from the normal PDF~\eqref{normal_pdf} as $E_i = Np_i$. Here $p_i$ is the probability that a random value sampled from $N(0,\sigma)$ is within the $i$-th interval. The intervals are given in Tab.~\ref{quant_io}, where $i$ is one of the Output values. $\ldots\cdots\ldotp\ldotp$

For each data frame the value of the test-statistic is calculated as

\begin{equation}
  \label{x2_calc}
  X^2 = \sum_{i=0}^3 \frac{(B_i - E_i)^2}{E_i}.
\end{equation}


The $X^2$ test-statistic asymptotically approaches the $\chi^2_{k=3}$ distribution, where $k = n - 1 = 3$ is the number of degrees of freedom. The $\chi^2_{k=3}$ PDF is shown in Fig.~\ref{chi2_pdf}. The statistic $X^2$ is a random value showing how close are the observation frequencies $B_i$ to the perfect, theoretical frequencies $E_i$. The $\chi^2_{k=3}$ PDF has maximum at $X^2=1$ and the mean at $X^2=k=3$. This means that if $X^2$ is distributed as $\chi^2_{k=3}$ its most probable random values will be concentrated somewhere around the mean 3 and not much further. But how much further? The area under the $\chi^2_{k=3}$ PDF curve in Fig.~\ref{chi2_pdf} over an interval $[a,b]$ equals to the probability that the random value will appear within this interval. If we want to be 95\% confident that the data is distributed normally, $X^2$ cannot exceed the critical value $\chi^2_{cr}$ such that the probability for $X^2$ to appear within the interval $[0 \twodots \chi^2_{cr}]$ is $p=0.95$. The critical $\chi^2_{k=3}$ value can be calculated as the value of $\chi^2$ Probability Point Function or PPF, the inverse of the $\chi^2$ Cumulative Distribution Function or CDF. In Python this is done as $\verb@scipy.stats.chi2.ppf(1-alpha, k)@$, where $\alpha = 0.05$ is the level of significance. In our case $\chi^2_{cr} = 7.81$. 

\begin{figure}[ht!]
  \begin{center}
  \includegraphics[width=25pc]{fig_chi2_pdf.eps}
  %\noindent\includegraphics[width=20pc]{fig_4_Level_Quantization_Pattern_impr.eps}
  %\includegraphics[width=\linewidth]{}
  \caption{\small Chi-squared distribution function.}
  \label{chi2_pdf}
  \end{center}
\end{figure}

Thus, our algorithm flags a channel data in frame as non-Gaussian if its $X^2 > 7.81$, the probability of incorrectly rejecting the null hypothesis being $\alpha = 0.05$. In Fig.~\ref{chi2_pdf} this is the red-filled area with the probability 0.05 over the range $[\chi^2_{cr} \twodots +\infty)$. 



\section{Estimation of Quantization Threshold Using Linear Search}

As mentioned, the M5B files do not contain the values of quantization threshold $\theta$, which is continuously being adjusted and can differ from one frame to the next. Assuming the data are sampled from the normally distributed population we can hypothesize that the $\theta_{\text{opt}}$ value that provides the best fit of the observed frequencies $B_i$ to the normal frequencies $E_i$ can be a good estimate of the actual $\theta$ established at the quantization time.

One can notice that the $X^2$ statistics in Eq.~\eqref{x2_calc} is a function of a single variable $\theta$: 

\begin{equation}
  \label{x2_func_of_theta}
  X^2(\theta) = \sum_{i=0}^3 \frac{(B_i - E_i(\theta))^2}{E_i(\theta)},
\end{equation}

where the normal frequencies $E_i$ are dependent on the quantization thresholds positions:

\begin{equation*}
  \label{norm_freq}
  E_{0\twodots3}(\theta) = N \left[\Phi(-\theta), \; \frac{1}{2}-\Phi(-\theta), \; 
                             \frac{1}{2}-\Phi(-\theta), \; \Phi(-\theta) \right],
\end{equation*}

as shown in Fig.~\ref{npdf_areas}, and $\Phi(x)$ is the normal CDF with $\mu=0$ and $\sigma=1$:

\begin{equation}
  \label{ncdf}
  \Phi(x) = \frac{1}{2} \left[1 + \erf \left( \frac{x}{\sqrt{2}} \right) \right].
\end{equation}


\begin{figure}[ht!]
  \begin{center}
  \includegraphics[width=25pc]{fig_npdf_areas.eps}
  \caption{\small  $\theta = 0.7988$, which can be used as an estimate for the actual threshold used in the analog signal quantization.}
  \label{npdf_areas}
  \end{center}
\end{figure}

Fig.~\ref{optimum_theta} shows that the curve $y = X^2(\theta)$ has the only minimum. Thus, the best fit of the normal frequencies $E_i$ to the observed frequencies $B_i$ can be reached at the single $\theta=\theta_\text{opt}$ value that provides minimum to $X^2(\theta)$. 

We have used a fast-converging Brent's algorithm for one-dimensional search. It is a combination of the golden section search at the beginning and the parabolic interpolation when the process is close enough to the minimum.


\begin{figure}[ht!]
  \begin{center}
  \includegraphics[width=25pc]{fig_optimal_quantization_threshold.eps}
  \caption{\small $X^2(\theta)$ from Eq.~\eqref{x2_func_of_theta} as the measure of error between the observed, $B_i$, and normal, $E_i$ frequencies for the range of quantization tresholds $[0.4 \mathinner{\ldotp\ldotp}1.5]$. The curve has minimum at $\theta = 0.7988$, which can be used as an estimate for the actual threshold used in the analog signal quantization.}
  \label{optimum_theta}
  \end{center}
\end{figure}


\section{Using Graphics Processing Units (GPU)}



%=====================================================================================

\section{NormTest Software}

This software is intended for fast testing for correctness of the Mark 5B output
files (m5b files) before the correlator. The 2-bit data streams in the m5b files
can be considered correct if they are samples from the Gaussian (normal)
distribution. We call such tests "testing for normality".

\subsection{gpu\_m5b.py}

Normality (Gaussianity) test for M5B files on either an Nvidia GPU using PyCUDA
package or a GPU using PyOpenCL package. Single precision floats.

This module provides "transparent" access to the GPU independent of the
software framework used, CUDA or OpenCL.

The module contains class normtest. It is not intended to create multiple
class instances (althoug it is surely possible). When imported, it 
probes the system to find what GPU frameworks are installed. It chooses
automatically between PyCUDA and OpenCL and initializes the relevant 
data structures. In case both frameworks are installed, it prefers
PyCUDA since it is ~1.5 times faster than PyOpenCL. \\


\text{--------- FUTURE WORK --------------------------- FUTURE WORK ----------------} \\
However, it is possible to overwrite the framework using the class method

Normtest.set_fw(fw="").

Parameter:
    fw: framework to use. It can be "cuda", "opencl", or None.
        If fw="", nothing changes. \\
\text{--------- FUTURE WORK --------------------------- FUTURE WORK ----------------}\\

    Class method Normtest.do_m5b(m5b_filename [, nthreads=8])

The normtest class provides a "class method" do_m5b(m5b_filename),
which runs the normality test on the available GPU and the software
framework selected. If the M5B file is large and it does not fit into either
system RAM or the GPU ram, it is processed in chunks. The results are saved 
in binary files.  The file have the following names:

    nt_<data>_<framework>_<m5b_basename>_<timestamp>.bin,

where <data> is the result types:

quantl: dtype=np.float32, shape=(n_frames,16,4), 4 quantiles for 16 channels;
chi2:   dtype=np.float32, shape=(n_frames,16), chi^2 for 16 channels;
thresh: dtype=np.float32, shape=(n_frames,16), quantization thresholds found
        for 16 channels;
flag:   dtype=np.uint16, shape=(n_frames,16), flags for 16 channels; 
niter:  dtype=np.uint16, shape=(n_frames,16), number of iterations of Brent's
        optimization method used to find the optimal quantization threshold
        for 16 channels;

   
Example:
   
from gpu_m5b import Normtest as nt
nt.do_m5b("rd1910_wz_268-1811.m5b")

Empirically, it has been found that the best performance is achieved 
with 8 threads per block (in CUDA terminology), and, which is the same, 
8 work items per work group (in OpenCL terms). However, this number can 
be changed using the nthreads parameter. For example:

nt.do_m5b("rd1910_wz_268-1811.m5b", nthreads=64)


---------------------------

This directory also contains two older versions ofthe Python scripts for
normality testing using the GPUs. One of them, normtest_m5b_cuda.py, uses
PyCuda and can be only run on Nvidia GPUs with CUDA and PyCuda installed.
The other one uses PyOpenCL and can be run on both AMD and Nvidia GPUs as
long as OpenCL and PyOpenCL are installed. Note that CUDA works ~1.5 times
faster than OpenCL.

Both scripts cannot process M5B files in chunks, and therefore they are unable
to process large M5B files.

Currently, the scripts use positional command line parameters.

2. normtest_m5b_cuda.py:

Normality (Gaussianity) test for M5B files on Nvidia GPU using PyCUDA package.
Single precision floats.

Requires:

ker_m5b_gauss_test.cu, CUDA kernel.
fminbndf.cu, 1D optimization code.

Usage:

\$ python normtest_m5b_cuda.py <m5b-file-name> [<of threads per block>] [-s]

Or, from IPython:

\$ ipython --pylab

%run normtest_m5b_cuda.py <m5b-file-name> [<# of threads per block>] [-s]

If <# of threads> is not specified, the optimal (appearingly) 8 is used.

If "-s" is present at the end of command line the results are saved in text
files in the subdirectory result/ with the names:
   thresholds_*.txt
   residuals_*.txt
   n_iterations_*.txt
   flags_*.txt
   quantiles_*.txt

Examples:

\$ python normtest_m5b_cuda.py rd1910_wz_268-1811.m5b
\$ python normtest_m5b_cuda.py rd1910_wz_268-1811.m5b 8
\$ python normtest_m5b_cuda.py rd1910_wz_268-1811.m5b 8 -s

Note that saving the result files may take long time.




3. normtest_m5b_ocl.py:

Normality (Gaussianity) test for M5B files on a GPU using PyOpenCL package.
Single precision floats.

Requires:
ker_m5b_gauss_test.cl, OpenCL kernel.
fminbndf.cl, 1D optimization code for Nvidia GPUs.
fminbndf_amd.cl, 1D optimization code for AMD GPUs.

Usage: 

\$ python normtest_m5b_cuda.py <m5b-file-name> [<# of threads per block>] [-s]

Or, from IPython:

\$ ipython --pylab

%run normtest_m5b_ocl_.py <m5b-file-name> [<of threads per block>] [-s]

If <# of threads> is not specified, the optimal (appearingly) 8 is used.

If "-s" is present at the end of command line the results are saved in text
files in the subdirectory result/ with the names:
   thresholds_*.txt
   residuals_*.txt
   n_iterations_*.txt
   flags_*.txt
   quantiles_*.txt

Examples:
")
\$ python normtest_m5b_ocl.py rd1910_wz_268-1811.m5b
\$ python normtest_m5b_ocl.py rd1910_wz_268-1811.m5b 8
\$ python normtest_m5b_ocl.py rd1910_wz_268-1811.m5b 8 -s

Note that saving the result files may take long time.


----------------------------

Ancillary scripts:

4. plot_m5b_thrange.py

Plots squared error (the residual) between M5B Data and four quantiles of the
standard normal distribution over the range [0.4 .. 1.5] of input sample
thresholds. The plot obviously has its minimum at the threshold +-0.817/STD
marked with the red dot.


5. test_m5b.py

Calculates the observed Chi^2 and compares it with the Chi^2 critical value at
the significance level 0.05 for the degrees of freedom 3 (we have 4 quantiles,
so df = 4 - 1 = 3).

Plots histograms of the observed data and the theoretical normal distribution
to compare.

Running:
%run test_m5b.py <m5b_filename>


6. plot_m5b_hist.py

Plots two histograms of the results from gpu_m5b.py for the whole 
M5B (or M5A) file: 
6.1. Distribution of chi^2 and a red marker showing position of the critical
     chi^2 value (7.81), as well as the percent of chi^2 exceeding it.
6.2. Distribution of the optimal quantization thresholds and a red marker
     showing position of the critical threshold value (0.6745 rms), as well as
     the percent of the thresholds that failed to reach it.


7. inspect_nt.py

This script creates 4x4 plots of 16 histograms for each of the 16 channels.
The plots are for one or several (averaged) frames. The histograms are compared
with the normal distribution curves showing approximately from what size
quantiles the observation data are drawn. For each plot the chi^2 is printed.

The data are read from the *.bin files created with the gpu_m5b_chi2.py.

Running:

%run inspect_nt.py <m5b_filename> <timestamp> <start_frame_#> <#_of_frames> 

Some interesting frames:
7.1. These plots show that the Pearson's chi^2 cannot be used. The histograms 
are very far from the normal distributions, but most of the chi^2 values
are very small and signal "normality"
%run inspect_nt.py rd1903_ft_100-0950.m5b 025 97737 1

7.2. These plots are definitely from the uniform distributions, and yet, most
of the chi^2 values are very small and signal "normality". The pearson's
criterion also does not work.
%run inspect_nt.py rd1903_ft_100-0950.m5b 025 4 1
%run inspect_nt.py rd1903_ft_100-0950.m5b 025 170578 1
%run inspect_nt.py rd1903_ft_100-0950.m5b 025 389930 1
%run inspect_nt.py rd1903_ft_100-0950.m5b 025 6832715 1

7.3. These plots show close to normal histograms with good chi^2 values, i.e.
< 7.81.
%run inspect_nt.py rd1910_wz_268-1811.m5b 970 200 1
%run inspect_nt.py rd1910_ny_269-1404.m5a 395 7139 1


8. plot_25pc_npdf_expectations.py

Plots the normal curve N(0,1) divided vertically into 4 equal areas under the 
curve (25%-quantiles). The division lines are at -0.6745, 0, and +0.6745. 
For each of the areas, the math expectations are computed, they are at 
    -1.27, -0.32, 0.32, and 1.27 (in STDs). 
Thse are the most probable analog signal values before the quantization with
the *ideal* thresholds -0.6745, 0, and +0.6745, which provide the uniform 
arrangement of the discrete signal in the 4 bins.  


9. skew_kurt.py

Calculates skewness and kurtosis of a frame in M5B or M5A file.
The data positions (in STDs) are assumed at the 25%-quantile math expectations,
  mu0 = -1.27, mu1 = -0.32, mu2 = 0.32, and mu3 = 1.27.





\end{document}



