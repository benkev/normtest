\documentclass[letterpaper,twoside,12pt]{article}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[T1]{fontenc}
\usepackage{natbib}
\usepackage{authblk}
\bibliographystyle{agu08}

\newcommand{\ud}{\mathrm d}
\newcommand{\uj}{\mathrm{j}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\Real}{\mathrm{Re}}
\newcommand{\Imag}{\mathrm{Im}}
\newcommand{\dif}{\mathrm{d}}
\newcommand{\sigsig}{\sigma_1\sigma_2}
\newcommand{\varss}{\varsigma_1\varsigma_2}
\newcommand{\hvarss}{\hat{\varsigma}_1 \hat{\varsigma}_2}


\title{Normality Test for 2-bit Stream Data in Mark-5 Files}

\author[1]{L. V. Benkevitch}
\affil[1]{\small MIT Haystack observatory, Westford, MA 01886, USA.}


\begin{document}

\maketitle

\begin{abstract}
The radio astronomy data from a single dish are recorded in M5B (Mark-5) or VDIF formatted files. The recorded data are supposed to be Gaussian white noise. A corrupted data segment can be spotted at the output of correlation stage. However, the correlation is expensive and vastly increases the bulk of data to be analyzed for spurious parts. Here we consider a problem of finding non~Gaussian (or non-normal) single-dish data segments in M5B files.

The problem may be thought about from a security standpoint. Suppose someone (a malicious character) wishes to hack a system and figures an approach would be to embed some malicious code in. Is it possible to detect the embedded (non-Gaussian) data within a frame or multiple frames before the correlator? Also, even though an algorithm can be determined, is it possible to ensure its implementation is fast enough? The data files are large (up to a hundred gigabytes).

At the current stage of work we only consider M5B files. The data in M5B format are streamed in 16 channels, 2-bit width each, resulted from a 4-level quantization. The 2-bit shortness of the integers with the 4 possible values, 0, 1, 2, and 3, makes it difficult to use standard statistical tests for normality, such as the one based on Pearson's $\chi^2$ test.     
 
We offer a solution based on comparing the data statistics with the corresponding quantiles of standard normal distribution. The algorithm runs on the GPU (Graphics Processing Unit), which provides high speed computations.
\end{abstract}


\section{Theory}

An M5B file can be considered as an array of data 10016-byte frames. Each frame consists of 2504 32-bit words (\verb@unsigned int@ or  \verb@uint@ in C/C++). The first 4 words comprise the frame header, so a frame has 2500 words of pure data. Each 32-bit data word is subdivided into 16 2-bit channels, numbered from 0 to 15. 

Consider an analog signal $x(t)$ and the result of its quantization $\hat{x}(t)$ streamed in a single channel. Our aim is obtaining components of the mathematical expectation of the quantizer output $\hat{x}(t)$. Here we follow the reasoning by [Schwab, 2002]. In general case, the quantization function $\hat{x} = q(x)$ is specified by a tuple of $n+1$ input voltage thresholds, 
$-\infty \equiv v_0 < v_1 < v_2 < \ldots  < v_{n-1} < v_n \equiv +\infty$, and a tuple of $n$ quantizer output levels, $\{ w_1, w_2, \ldots w_n \}$. The quantizer outputs $q(x) = w_k$ whenever $v_{k-1} < x < v_k$.

The input voltage $x(t)$ is expected to be sampled from the normal distribution with the mean $\mu$ and the standard deviation $\sigma$, characterized by the probability density function (PDF) 

\begin{equation}
  \label{normal_pdf}
  p(x) =  \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{•(x-\mu)^2}{2\sigma^2}}.
\end{equation}

Then the expectation of the quantizer output is

\begin{equation}
  \label{x_expect}
  [\hat{x}] = \sum_{i=1}^n \int_{v_{i-1}}^{v_i} w_i \, p(x) \, \ud x =  
  \sum_{i=1}^n w_i \int_{v_{i-1}}^{v_i} \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{•(x-\mu)^2}{2\sigma^2}} \, \ud x.
\end{equation}

The latter integrals are called quantiles of the normal distribution,

\begin{equation}
  \label{quantile}
  Q(v_{i-1}, v_i) = \frac{1}{\sigma\sqrt{2\pi}} \int_{v_{i-1}}^{v_i} e^{-\frac{•(x-\mu)^2}{2\sigma^2}} \, \ud x,
\end{equation}

and Eq.~\eqref{x_expect} can be rewritten as

\begin{equation}
  \label{x_expect_quantile}
  [\hat{x}] = \sum_{i=1}^n { w_i Q(v_{i-1}, v_i)}.
\end{equation}

As we can see, a quantile $Q(v_{i-1}, v_i) = Q_i$ is the probability that quantizer output equals $w_i$ when the input voltage falls within the interval $[v_{i-1} \ldots {v_i}]$. Its expectation, $[\hat{x}]$, is not as useful (for a symmetric quantizer and zero-centered Gaussian noise it equals zero anyway) as its components in Eq.~\eqref{x_expect_quantile}.

Suppose a channel data segment has $N$ numbers total, and each quantizer output $w_i$ occurs $N_i$ times, so $N = N_1 + N_2 + \ldots + N_n$. As the real-world data in a channel are sampled from the Gaussian distribution, we should expect that the quantizer outputs $w_i$ occur at the relative frequencies $\hat{Q_i} = N_i / N$, converging to the theoretical Gaussian quantiles $Q_i$ with growing $N$. Hence the measure of normality, i.e. proximity of the empirical data to the Gaussian distribution, can be experssed as

\begin{equation}
  \label{q_err}
  \varepsilon^2 = \sum_{i=1}^n {(\hat{Q_i} - Q_i)^2}.
\end{equation}

The squared error $\varepsilon^2$ is distributed as $\chi^2$



















.\linebreak[4] \linebreak[4] \linebreak[4]


In our case, the quantizer has three threshold voltage levels.



\end{document}



